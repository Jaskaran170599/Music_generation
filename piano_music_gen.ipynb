{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import music21 as ms\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Dropout,Activation,Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating data\n",
    "\n",
    "## return a list consisting of pitch id of note and note id separated by dot in a chord \n",
    "\n",
    "## if the file has several instruments it takes only one in account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"data\"\n",
    "def datagen(files=48):\n",
    "    notes=[]\n",
    "    j=os.listdir(\"data\")\n",
    "    for i in range(files):\n",
    "        midi=ms.converter.parse(path+\"//\"+j[i])\n",
    "        \n",
    "        notes_file=ms.instrument.partitionByInstrument(midi)\n",
    "        \n",
    "        if notes_file:\n",
    "            notes_file=notes_file[0].recurse()\n",
    "            \n",
    "        else:\n",
    "            notes_file=notes_file.flat.notes\n",
    "        \n",
    "        for k in notes_file:\n",
    "            if isinstance(k,ms.note.Note):\n",
    "                notes.append(str(k.pitch))\n",
    "            if isinstance(k,ms.chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in k.normalOrder))\n",
    "        print(i,end=\" \")       \n",
    "    return notes\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 "
     ]
    }
   ],
   "source": [
    "\n",
    "#48 total files\n",
    "note=datagen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Mapping of pitches(string data) to numbers\n",
    "\n",
    "# And creating dataset with lookback 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitchesname=sorted(set(note))    \n",
    "# mapp=dict((note, number) for number, note in enumerate(pitchesname))\n",
    "\n",
    "# def mapping(note,lookback=100):\n",
    "#     x=[]\n",
    "#     y=[]\n",
    "    \n",
    "#     for i in range(0,len(note)-lookback,1):\n",
    "# #         print(i,end=\" \")\n",
    "#         x.append(np.array([mapp[j] for j in note[i:i+lookback]]))\n",
    "#         y.append(np.array([mapp[note[i+lookback]]]))\n",
    "#     x=np.array(x)\n",
    "#     y=np.array(y)\n",
    "#     x=x.reshape((x.shape[0],lookback))\n",
    "    \n",
    "#     return x,y,len(pitchesname)\n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_x,data_y,n_vocab=mapping(note)\n",
    "# data_x.shape,data_y.shape,n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# input_file=open(\"input_file\",\"wb\")\n",
    "# output_file=open(\"output_file\",\"wb\")\n",
    "# pickle.dump(data_x,input_file)\n",
    "# pickle.dump(data_y,output_file)\n",
    "# output_file.close()\n",
    "# input_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model(input_shape1,n_voacb):\n",
    "#     model=Sequential()\n",
    "#     model.add(Embedding(input_dim=n_voacb+1,output_dim=256))\n",
    "# #     model.add(LSTM(256,return_sequences=True))\n",
    "# #     model.add(Dropout(0.3))\n",
    "# #     model.add(LSTM(512, return_sequences=True))\n",
    "# #     model.add(Dropout(0.3))\n",
    "#     model.add(LSTM(256))\n",
    "#     model.add(Dense(256))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(Dense(n_vocab))\n",
    "#     model.add(Activation('softmax'))\n",
    "#     model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop',metrics=['accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=create_model(data_x.shape[1:],n_vocab)\n",
    "# n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.fit(data_x[:500],data_y[:500],epochs=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model(\"musicmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmapp=dict((number,note) for number, note in enumerate(pitchesname))\n",
    "def generate_notes(model,start,n=10):\n",
    "    pred_notes=[]\n",
    "    start=list(start)\n",
    "    k=1\n",
    "    for i in range(n):\n",
    "        s=np.reshape(start,(1,100))\n",
    "        if(k%10==0):\n",
    "            s=np.random.randint(0,317,size=(1,100))\n",
    "        pred=np.argmax(model.predict(s),axis=1)\n",
    "        result=dmapp[pred[0]]\n",
    "        pred_notes.append(result)\n",
    "        start.append(pred[0])\n",
    "        start=start[1:]\n",
    "    return pred_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n=np.random.randint(0,len(data_x)-1)\n",
    "arr=np.random.randint(0,317,size=(100))\n",
    "gen_notes=generate_notes(model,arr,n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([106, 244, 140,  87,   1, 273, 128, 244, 116, 238, 124, 229, 294,\n",
       "       268,  61, 128, 286,  77, 144,  16, 251,  41, 274,  32, 314, 131,\n",
       "       255,  62, 237,   6,  33, 210,  76,  17,  50, 215,  79,  18, 202,\n",
       "       260, 314,  92, 280, 212, 143, 282, 256,  44,  61,  96, 295, 277,\n",
       "       286, 110, 290,  91, 145,  26, 104,  39, 150, 253, 211,  96, 220,\n",
       "       216,  64, 154, 175, 219, 308, 264, 227,  12, 182,  80, 214, 241,\n",
       "       229,  91, 184, 218, 251, 190, 260, 209,  43, 142, 256, 143, 231,\n",
       "        87,  90,  12, 248, 295, 241, 225, 233, 243])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genstream(pred_notes):\n",
    "    offset=0\n",
    "    gen_stream=[]\n",
    "    for i in pred_notes:\n",
    "        if ((\".\" in i) or (i.isdigit())):\n",
    "            notesinc=i.split(\".\")\n",
    "            note=[]\n",
    "            for j in notesinc:\n",
    "                newnote=ms.note.Note(int(j))\n",
    "                newnote.storedInstrument=ms.instrument.Banjo()\n",
    "                note.append(newnote)\n",
    "            newchord=ms.chord.Chord(note)\n",
    "            newchord.offset=offset\n",
    "            gen_stream.append(newchord)\n",
    "        else:\n",
    "            newnote=ms.note.Note(i)\n",
    "            newnote.storedInstrument=ms.instrument.Bagpipes()\n",
    "            newnote.offset=offset\n",
    "            gen_stream.append(newnote)\n",
    "        \n",
    "        offset+=0.5\n",
    "    return gen_stream\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_music=genstream(gen_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<music21.note.Note A>,\n",
       " <music21.note.Note F#>,\n",
       " <music21.note.Note E->,\n",
       " <music21.note.Note F#>,\n",
       " <music21.note.Note A>,\n",
       " <music21.note.Note F#>,\n",
       " <music21.note.Note E->,\n",
       " <music21.note.Note F#>,\n",
       " <music21.note.Note F#>,\n",
       " <music21.note.Note F#>,\n",
       " <music21.note.Note E->,\n",
       " <music21.note.Note A>,\n",
       " <music21.note.Note C>,\n",
       " <music21.note.Note G#>,\n",
       " <music21.note.Note D>,\n",
       " <music21.note.Note E->,\n",
       " <music21.note.Note E->,\n",
       " <music21.note.Note D>,\n",
       " <music21.note.Note C>,\n",
       " <music21.note.Note C>,\n",
       " <music21.note.Note G#>,\n",
       " <music21.note.Note G#>,\n",
       " <music21.note.Note E->,\n",
       " <music21.note.Note G#>,\n",
       " <music21.note.Note F#>,\n",
       " <music21.note.Note G#>,\n",
       " <music21.note.Note G#>,\n",
       " <music21.note.Note G>,\n",
       " <music21.note.Note E->,\n",
       " <music21.note.Note G#>,\n",
       " <music21.note.Note F#>,\n",
       " <music21.note.Note G#>,\n",
       " <music21.note.Note G#>,\n",
       " <music21.note.Note G#>,\n",
       " <music21.note.Note E->,\n",
       " <music21.note.Note A>,\n",
       " <music21.note.Note C>,\n",
       " <music21.note.Note G#>,\n",
       " <music21.note.Note A>,\n",
       " <music21.note.Note G#>,\n",
       " <music21.note.Note E->,\n",
       " <music21.note.Note F>,\n",
       " <music21.note.Note E>,\n",
       " <music21.note.Note G#>,\n",
       " <music21.note.Note F>,\n",
       " <music21.note.Note F>,\n",
       " <music21.note.Note F>,\n",
       " <music21.note.Note E>,\n",
       " <music21.note.Note F>,\n",
       " <music21.note.Note F>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_output3.mid'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_stream=ms.stream.Stream(gen_music)\n",
    "midi_stream.write('midi',fp='test_output3.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
